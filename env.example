# AI 提供商配置
# AI_PROVIDER：要使用的提供商
# 選項：bedrock, openai, anthropic, google, vertexai, azure, ollama, openrouter, deepseek, siliconflow, gateway
# 預設值：bedrock
AI_PROVIDER=bedrock

# AI_MODEL：您選擇的提供商的模型 ID（必需）
AI_MODEL=global.anthropic.claude-sonnet-4-5-20250929-v1:0

# AWS Bedrock 配置
# AWS_REGION=us-east-1
# AWS_ACCESS_KEY_ID=your-access-key-id
# AWS_SECRET_ACCESS_KEY=your-secret-access-key
# 注意：Claude 和 Nova 模型支援推理/擴展思考
# BEDROCK_REASONING_BUDGET_TOKENS=12000  # 選擇性：Claude 推理預算（以 Token 計）(1024-64000)
# BEDROCK_REASONING_EFFORT=medium        # 選擇性：Nova 推理工作量(low/medium/high)

# OpenAI 配置
# OPENAI_API_KEY=sk-...
# OPENAI_BASE_URL=https://api.openai.com/v1  # 選擇性：自訂 OpenAI 相容端點
# OPENAI_ORGANIZATION=org-...  # 選擇性
# OPENAI_PROJECT=proj_...      # 選擇性
# 注意：o1/o3/gpt-5 模型自動啟用推理摘要（預設值：詳細）
# OPENAI_REASONING_EFFORT=low   # 選擇性：推理工作量(minimal/low/medium/high) - 用於 o1/o3/gpt-5
# OPENAI_REASONING_SUMMARY=detailed  # 選擇性：覆寫推理摘要(none/brief/detailed)

# Anthropic（直接）配置
# ANTHROPIC_API_KEY=sk-ant-...
# ANTHROPIC_BASE_URL=https://your-custom-anthropic/v1
# ANTHROPIC_THINKING_TYPE=enabled            # 選擇性：Anthropic 擴展思考(enabled)
# ANTHROPIC_THINKING_BUDGET_TOKENS=12000     # 選擇性：擴展思考的預算（以 Token 計）

# Google 生成式 AI 配置
# GOOGLE_GENERATIVE_AI_API_KEY=...
# GOOGLE_BASE_URL=https://generativelanguage.googleapis.com/v1beta  # 選擇性：自訂端點
# GOOGLE_CANDIDATE_COUNT=1                   # 選擇性：要生成的候選數量
# GOOGLE_TOP_K=40                            # 選擇性：Top K 採樣參數
# GOOGLE_TOP_P=0.95                          # 選擇性：Nucleus 採樣參數
# 注意：Gemini 2.5/3 模型自動啟用推理顯示(includeThoughts: true)
# GOOGLE_THINKING_BUDGET=8192                # 選擇性：Gemini 2.5 思考預算（以 Token 計）(更多/更少思考)
# GOOGLE_THINKING_LEVEL=high                 # 選擇性：Gemini 3 思考等級(low/high)

# Google Vertex AI 配置（企業 GCP）
# 適用於需要資料駐留、VPC 服務控制項或 GCP 整合的企業使用者
# GOOGLE_VERTEX_API_KEY=                          # 必需：Express Mode API 金鑰
# GOOGLE_VERTEX_BASE_URL=https://...              # 選擇性：自訂端點 URL
# 注意：Gemini 2.5/3 模型自動啟用推理顯示(includeThoughts: true)
# GOOGLE_VERTEX_THINKING_BUDGET=8192              # 選擇性：Gemini 2.5 思考預算（以 Token 計）(1024-100000)
# GOOGLE_VERTEX_THINKING_LEVEL=high               # 選擇性：Gemini 3 思考等級(minimal/low/medium/high)

# Azure OpenAI 配置
# 使用下列其中一種方法設定端點：
#   1. AZURE_RESOURCE_NAME - SDK 建構：https://{name}.openai.azure.com/openai/v1{path}
#   2. AZURE_BASE_URL - SDK 將 /v1{path} 附加到您的 URL
# 如果兩者都設定，AZURE_BASE_URL 優先。
# AZURE_RESOURCE_NAME=your-resource-name
# AZURE_API_KEY=...
# AZURE_BASE_URL=https://your-resource.openai.azure.com/openai  # 替代方案：自訂端點
# AZURE_REASONING_EFFORT=low                 # 選擇性：Azure 推理工作量(low, medium, high)
# AZURE_REASONING_SUMMARY=detailed

# Ollama（本機）配置
# OLLAMA_BASE_URL=http://localhost:11434/api  # 選擇性，預設值為 localhost
# OLLAMA_ENABLE_THINKING=true                 # 選擇性：為支援的模型啟用思考(例如 qwen3)

# OpenRouter 配置
# OPENROUTER_API_KEY=sk-or-v1-...
# OPENROUTER_BASE_URL=https://openrouter.ai/api/v1  # 選擇性：自訂端點

# DeepSeek 配置
# DEEPSEEK_API_KEY=sk-...
# DEEPSEEK_BASE_URL=https://api.deepseek.com/v1  # 選擇性：自訂端點

# SiliconFlow 配置（OpenAI 相容）
# 基底域可為 .com 或 .cn，預設為 https://api.siliconflow.com/v1
# SILICONFLOW_API_KEY=sk-...
# SILICONFLOW_BASE_URL=https://api.siliconflow.com/v1  # 選擇性：如需切換，請使用 https://api.siliconflow.cn/v1

# SGLang 配置（OpenAI 相容）
# SGLANG_API_KEY=your-sglang-api-key
# SGLANG_BASE_URL=http://127.0.0.1:8000/v1  # 您的 SGLang 端點

# ModelScope 配置
# MODELSCOPE_API_KEY=ms-...
# MODELSCOPE_BASE_URL=https://api-inference.modelscope.cn/v1  # 選擇性：自訂端點

# ByteDance 豆包配置（透過 Volcengine）
# DOUBAO_API_KEY=your-doubao-api-key
# DOUBAO_BASE_URL=https://ark.cn-beijing.volces.com/api/v3  # ByteDance Volcengine 端點

# Vercel AI Gateway 配置
# 從此處取得您的 API 金鑰：https://vercel.com/ai-gateway
# 模型格式："provider/model"，例如 "openai/gpt-4o"、"anthropic/claude-sonnet-4-5"
# AI_GATEWAY_API_KEY=...
# AI_GATEWAY_BASE_URL=https://your-custom-gateway.com/v1/ai  # 選擇性：自訂 Gateway URL（用於本機開發或自我託管 Gateway）
#                                                              # 如未設定，使用 Vercel 預設值：https://ai-gateway.vercel.sh/v1/ai

# Langfuse 可觀測性（選擇性）
# 啟用 LLM 追蹤和分析 - https://langfuse.com
# LANGFUSE_PUBLIC_KEY=pk-lf-...
# LANGFUSE_SECRET_KEY=sk-lf-...
# LANGFUSE_BASEURL=https://cloud.langfuse.com  # EU 地區，美國地區請使用 https://us.cloud.langfuse.com

# 選擇性伺服器端多模型配置
# 如果設定，指向包含伺服器提供模型的 JSON 檔案（參閱 README 以了解架構）。
# 預設值：專案根目錄中的 ./ai-models.json
# AI_MODELS_CONFIG_PATH=/path/to/ai-models.json

# 溫度（選擇性）
# 控制 AI 回應中的隨機性。數值越低 = 更具確定性。
# 對於不支援溫度的模型（例如 GPT-5.1 推理模型），請留空
# TEMPERATURE=0

# 存取控制（選擇性）
# ACCESS_CODE_LIST=your-secret-code,another-code

# Draw.io 配置（選擇性）
# NEXT_PUBLIC_DRAWIO_BASE_URL=https://embed.diagrams.net  # 預設值：https://embed.diagrams.net
# 使用此選項指向自我託管的 draw.io 執行個體

# 子目錄部署（選擇性）
# 若要部署到子目錄（例如 https://example.com/nextaidrawio）
# 設定此值為您的子目錄路徑，附加前導斜線（例如 /nextaidrawio）
# 根部署（預設值）請留空
# NEXT_PUBLIC_BASE_PATH=/nextaidrawio

# PDF 輸入功能（選擇性）
# 啟用 PDF 檔案上傳以提取文字並生成圖表
# 預設啟用。設定為「false」以停用。
# ENABLE_PDF_INPUT=true
# NEXT_PUBLIC_MAX_EXTRACTED_CHARS=150000  # PDF/文字提取的最大字元數（預設值：150000）

# 安全性設定（選擇性）
# 允許私人/內部 URL 用於反向代理設定（預設值：true）
# 設定為「false」以封鎖私人 IP、本機主機和內部主機名稱
# ALLOW_PRIVATE_URLS=false
